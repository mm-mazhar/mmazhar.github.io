<!DOCTYPE HTML>
<!--
	Portfolio: M. Mazhar
-->
<html>
	<head>
		<title>Portfolio | Mazhar</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link href="http://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.3.0/css/font-awesome.css" rel="stylesheet"  type='text/css'>
		<!-- <link rel="preconnect" href="https://fonts.googleapis.com">
		<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
		<link rel="stylesheet" type="text/css" href="//fonts.googleapis.com/css?family=Permanent+Marker" /> -->
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">
				<!-- Main -->
					<div id="main">
						<div class="inner">

							<!-- Header -->
								<header id="header">
									<a href="./" class="logo"><strong>M. Mazhar</strong></a>
									<ul class="icons">
										<!-- <li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li> -->
										<li><a href="https://github.com/mm-mazhar/mazhar" target="_blank" class="icon brands fa-github"><span class="label">Github</span></a></li>
										<li><a href="https://www.kaggle.com/mazhar01" target="_blank" class="icon brands fa-kaggle"><span class="label">kaggle</span></a></li>
										<li><a href="https://www.linkedin.com/in/m-mazhar-121133269/" target="_blank" class="icon brands fa-linkedin"><span class="label">Linkedin</span></a></li>
										<!-- <li><a href="https://twitter.com/mm_mazhar19" target="_blank" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li> -->
										<li><a href="https://wa.me/+923002576068" target="_blank" class="icon brands fa-whatsapp"><span class="label"></span></a></li>
										<!-- <li><a href="#" target="_blank" class="icon brands fa-snapchat-ghost"><span class="label">Snapchat</span></a></li>
										<li><a href="#" target="_blank" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
										<li><a href="#" target="_blank" class="icon brands fa-medium-m"><span class="label">Medium</span></a></li> -->
									</ul>
								</header>

							<!-- Content -->
                            <section>
                                <header class="main">
                                    <h2>ML/DL and Computer Vision</h2>
                                    
                                    <ul class="icons icons-badges">
                                        <li><span class="label"><img src="https://img.shields.io/badge/Jupyter-Notebook-F37626?style=plastic&logo=Jupyter"/></span></li>
                                        <li><span class="label"><img src="https://img.shields.io/badge/Python->3.7-3776AB?style=plastic&logo=Python"/></span></li>
                                        <li><span class="label"><img src="https://img.shields.io/badge/Tensoflow-FF6F00?style=plastic&logo=Tensoflow"/></span></li>
                                        <!-- <li><span class="label"><img src="https://img.shields.io/badge/scikit-learn-F7931E?style=plastic&logo=scikit-learn"/></span></li> -->
                                        <li><span class="label"><img src="https://img.shields.io/badge/Numpy-073343?style=plastic&logo=Numpy"/></span></li>
                                        <li><span class="label"><img src="https://img.shields.io/badge/pandas-150458?style=plastic&logo=pandas"/></span></li>
                                        <li><span class="label"><img src="https://img.shields.io/badge/matplotlib-366f81?style=plasticlogo=matplotlib"/></span></li>
                                        <li><span class="label"><img src="https://img.shields.io/badge/seaborn-adafc2?style=plastic&logo=seaborn"/></span></li>
                                        <li><span class="label"><img src="https://img.shields.io/badge/Streamlit-FF4B4B?style=plastic&logo=Streamlit"/></span></li>
                                        <li><span class="label"><img src="https://img.shields.io/badge/Docker-000000?style=plastic&logo=Docker"/></span></li>
                                        <li><span class="label"><img src="https://img.shields.io/badge/FastAPI-000000?style=plastic&logo=FastAPI"/></span></li>
                                        <li><span class="label"><img src="https://img.shields.io/badge/CircleCI-000000?style=plastic&logo=CircleCI"/></span></li>
                                        <li><span class="label"><img src="https://img.shields.io/badge/CircleCI-000000?style=plastic&logo=CircleCI"/></span></li>
                                        
                                    </ul>
                                    <hr>
                                </header>
                                <!-- Machine/Deep Learning and Computer Vision Projects -->
                                    <!-- <h2 id="elements">Machine/Deep Learning and Computer Vision</h2> -->
                                    <div class="row gtr-200">
                                        <div class="col-6 col-12-small">
                                            <!-- Next -->
                                            <h2>Soil Nutrient Prediction for Enhanced Fertilizer Recommendations</h2>
                                            <div align="center">
                                                <span class="label"><a href="https://github.com/mm-mazhar/IPAGE" target="_blank"><img alt="IPAGE" src="https://img.shields.io/badge/Github-Repo-blue"></a></span>
                                                <span class="label"><a href="javascript:void(0);" style="pointer-events: none;"><img alt="Python 3.10" src="https://img.shields.io/badge/Python-356c9b"/></a></span>
                                                <span class="label"><a href="https://github.com/OmdenaAI/ipage" target="_blank"><img alt="Main `IPAGE` Github Repo" src="https://img.shields.io/badge/Main `IPAGE` Github-Repo-blue"></a></span>
                                                <span class="label"><a href="https://ipage-app.streamlit.app/" target="_blank"><img alt="Steamlit" src="https://img.shields.io/badge/Streamlit-000000?style=social&logo=streamlit"></a></span>
                                                <span class="label"><a href="https://ipage.onrender.com/" target="_blank"><img alt="FastAPI" src="https://img.shields.io/badge/FastAPI-000000?style=social&logo=FastAPI"></a></span>
                                                <span class="label"><a href="javascript:void(0);" target="_blank"><img alt="MLFlow" src="https://img.shields.io/badge/MLFlow-000000?style=social&logo=mlflow"></a></span>
                                             </div>
                                             <br>
                                                <p style="text-align: justify; text-justify: inter-word;">
                                                    <span class="image right">
                                                        <a href="./images/to_be_issued.png" target="_blank">
                                                            <img src="./images/omdena-ipage-cert.png" alt="" style="width:416; height:256" />
                                                        </a>
                                                    </span>
                                                    Certificate To be Issued
                                                    Contributed in EDA, Developed Models for SOC, Boron, Experiment Tracking using MLFlow, Zn, API using FastAPI, Streamlit App for PoC.
                                                </p>
                                                <p style="text-align: justify; text-justify: inter-word;">
                                                    <p><a href="https://www.omdena.com/projects/soil-nutrient-prediction-for-enhanced-fertilizer-recommendations" target="_blank">Omdena Challenge Details</a></p>
                                                    <p><a href="https://ipage-app.streamlit.app/" target="_blank">Streamlit App</a></p>
                                                    <p><a href="https://ipage.onrender.com/" target="_blank">FastAPI</a></p>
                                                    <p>More on Github &nbsp; <a href="https://github.com/mm-mazhar/IPAGE" target="_blank" class="icon brands fa-github fa-2x"><span class="label">Github</span></a></p>
                                                </p>
                                                <!-- <br> -->
                                                <hr>
                                            <!-- Next -->
                                            <h2>3D Roof Reconstruction with Computer Vision for Solar Energy Optimization</h2>
                                            <div align="center">
                                                <span class="label"><a href="https://github.com/mm-mazhar/IECO" target="_blank"><img alt="3D Roof Reconstruction with Computer Vision for Solar Energy Optimization" src="https://img.shields.io/badge/Github-Repo-blue"></a></span>
                                                <span class="label"><a href="javascript:void(0);" style="pointer-events: none;"><img alt="Python 3.10" src="https://img.shields.io/badge/Python-356c9b"/></a></span>
                                                <span class="label"><a href="https://github.com/OmdenaAI/IECO" target="_blank"><img alt="Main `IECO` Github Repo" src="https://img.shields.io/badge/Main `IECO` Github-Repo-blue"></a></span>
                                             </div>
                                             <br>
                                                <p style="text-align: justify; text-justify: inter-word;">
                                                    <span class="image left">
                                                        <a href="./images/omdena-ieco-cert.png" target="_blank">
                                                            <img src="./images/omdena-ieco-cert.png" alt="" style="width:416; height:256" />
                                                        </a>
                                                    </span>
                                                    PointNet-based segmentation model (PointNetSeg) for point cloud data.
                                                    The model is designed to classify each point in a point cloud into a predefined set of classes, leveraging a combination of feature and spatial transformations.
                                                    The PointNetSeg model processes the transformed features to perform point-wise segmentation. The model’s final layer predicts the class of each point.
                                                    Input: Point cloud of shape (batch_size, num_points, 3), where each point has 3 coordinates (x, y, z).
                                                    Output: Class scores for each point in the point cloud, with a shape of (batch_size, num_classes, num_points).
                                                </p>
                                                <p style="text-align: justify; text-justify: inter-word;">
                                                    <p><a href="https://www.omdena.com/projects/3d-roof-reconstruction-with-computer-vision-for-solar-energy-optimization" target="_blank">Omdena Challenge Details</a></p>
                                                    <p>More on Github &nbsp; <a href="https://github.com/mm-mazhar/IECO" target="_blank" class="icon brands fa-github fa-2x"><span class="label">Github</span></a></p>
                                                </p>
                                                <!-- <br> -->
                                                <hr>
                                            <!-- Next -->
                                            <h2>Identifying Potential Areas for Urban Agriculture in Milan - Italy</h2>
                                            <div align="center">
                                                <span class="label"><a href="https://github.com/maria-fisher/Urban-Agriculture-in-Milan" target="_blank"><img alt="Identifying Potential Areas for Urban Agriculture in Milan - Italy Repo" src="https://img.shields.io/badge/Github-Repo-blue"></a></span>
                                                <span class="label"><a href="https://www.kaggle.com/datasets/mazhar01/identify-potential-areas-for-urban-agriculture/data" target="_blank"><img alt="Collected Dataset" src="https://img.shields.io/badge/Collected%20Dataset-blue"></a></span>
                                                <span class="label"><a href="javascript:void(0);" style="pointer-events: none;"><img alt="Python 3.10" src="https://img.shields.io/badge/Python-356c9b"/></a></span>
                                                <span class="label"><a href="javascript:void(0);" style="pointer-events: none;"><img alt="Python 3.10" src="https://img.shields.io/badge/JavaScript-efd81d"/></a></span>
                                                <span class="label"><a href="javascript:void(0);" style="pointer-events: none;"><img alt="Python 3.10" src="https://img.shields.io/badge/Streamlit-ff2b2b"/></a></span>
                                                <span class="label"><a href="javascript:void(0);" style="pointer-events: none;"><img alt="Python 3.10" src="https://img.shields.io/badge/GIS-c39f0b"/></a></span>
                                             </div>
                                             <br>
                                                <p style="text-align: justify; text-justify: inter-word;">
                                                    <span class="image right">
                                                        <a href="./images/omdena-ipaua-cert.png" target="_blank">
                                                            <img src="./images/omdena-ipaua-cert.png" alt="" style="width:416; height:256" />
                                                        </a>
                                                    </span>
                                                    Contributed mainly in task 1 of the Omdena challenge, which includes, data collection from Google Earth Engine, EDA and visualization, unsupervised modeling and web app development. Collected dataset from Google Earth Engine is now uploaded to  
                                                    <a href="https://www.kaggle.com/datasets/mazhar01/identify-potential-areas-for-urban-agriculture/data" target="_blank">kaggle</a>.
                                                </p>
                                                <p style="text-align: justify; text-justify: inter-word;">
                                                    <p><a href="https://www.omdena.com/chapter-challenges/identifying-potential-areas-for-urban-agriculture-in-milan-italy" target="_blank">Omdena Challenge Details</a></p>
                                                    <p><a href="https://drive.google.com/file/d/1iAeaTzuRiVOMaBhEHjqKjItOnK9r9FKy/edit" target="_blank">Streamlit App</a></p>
                                                    <p>More on Github &nbsp; <a href="https://github.com/maria-fisher/Urban-Agriculture-in-Milan" target="_blank" class="icon brands fa-github fa-2x"><span class="label">Github</span></a></p>
                                                </p>
                                                <!-- <br> -->
                                                <hr>
                                            <!-- Next -->
                                            <h2>Regression Model Pipeline</h2>
                                            <h4>From Data Scraping to Deployment: using, PyPI Model Packaging, FastAPI App deployed on Railway/Render</h4>
                                            <h5>Since Railway has stopped it's free tier, App is now deployed on Render</h5>
                                                <div align="center">
                                                    <span class="label"><a href="https://github.com/mm-mazhar/Scraping-Zameen.com" target="_blank"><img alt="Github Data Scraping Repo" src="https://img.shields.io/badge/Github-Data%20Scraping%20Repo-blue"></a></span>
                                                    <span class="label"><a href="https://www.kaggle.com/datasets/mazhar01/real-state-website-data" target="_blank"><img alt="Download Data From Kaggle" src="https://img.shields.io/badge/kaggle-Data-blue"></a></span>
                                                    <span class="label"><a href="https://deploying-ml-lasso-regression-model.onrender.com" target="_blank"><img alt="Predict API" src="https://img.shields.io/badge/FastAPI-Predict%20API-blue"></a></span>
                                                    <span class="label"><a href="https://pypi.org/project/lasso-regression-model/" target="_blank"><img alt="PyPI" src="https://img.shields.io/pypi/v/lasso-regression-model?logo=PyPi&style=Flat"></a></span>
                                                    <!-- <span class="label"><a href="javascript:void(0);" style="pointer-events: none;"><img alt="CircleCI" src="https://img.shields.io/circleci/build/github/mm-mazhar/Deploying-ML-Lasso-Regression-Model/main?logo=circleci&style=Flat"></a></span> -->
                                                    <!-- <span class="label"><a href="https://deploying-ml-lasso-regression-model.onrender.com" target="_blank"><img alt="Railway/Render APP" src="https://img.shields.io/badge/Render-000000?style=Flat&logo=Render"/></a></span> -->
                                                    <!-- <span class="label"><a href="https://github.com/mm-mazhar/Deploying-ML-Lasso-Regression-Model/tree/main/5.deploying_with_containers" target="_blank"><img src="https://img.shields.io/badge/Docker-000000?style=Flat&logo=Docker"/></a></span> -->
                                                </div>
                                                <br>
                                                <p style="text-align: justify; text-justify: inter-word;">
                                                        <span class="image left">
                                                            <a href="./images/main_image.png" target="_blank">
                                                                <img src="./images/main_image.png" alt=""  />
                                                            </a>
                                                        </span>
                                                    <b>Key Features</b>
                                                    <li>Collection of data via scraping a real estate website, data processing and cleaning.</li>
                                                    <li>Feature engineering using libraries like pandas, numpy, SK-Learn, and Feature Engine.</li>
                                                    <li>Building a robust ML pipeline with Lasso Regression Model training and fine-tuning.</li>
                                                    <li>Packaging and uploading the model to PyPi for easy integration and deployment.</li>
                                                    <li>Implementation of best practices with emphasis on testing using Pytest and Tox.</li>
                                                    <li>Exposing trained ML model using FastAPI, a modern and efficient web framework.</li>
                                                    <!-- <li>CI/CD with CircleCI for automated building, testing, and deployment.</li> -->
                                                    <!-- <li>Utilizing Docker for streamlined deployment to the Railway Platform.</li> -->
                                                    <!-- <li>Encapsulation of the entire application, including dependencies and environment, within a Docker container.</li> -->
                                                    
                                                    
                            
                                                </p>
                                                <p style="text-align: justify; text-justify: inter-word;">More on Github &nbsp; <a href="https://github.com/mm-mazhar/Deploying-ML-Lasso-Regression-Model-Render" target="_blank" class="icon brands fa-github fa-2x"><span class="label">Github</span></a></p>
                                                <!-- <br> -->
                                                <hr>
                                            <!-- Next -->
                                            <h2>Automatic Number Plate Recognition and EasyOCR</h2>
                                                <p style="text-align: justify; text-justify: inter-word;">
                                                    <span class="image right">
                                                        <a href="./images/anpr.jpg" target="_blank">
                                                            <img src="./images/anpr.jpg" alt="" style="width:416; height:256" />
                                                        </a>
                                                    </span>
                                                    This exercise is an implementation of Automatic Number Plate Recognition (ANPR) using EasyOCR library in Python. The goal of this exercise is to automatically recognize license plate numbers from an image, 
                                                    live camera or a video by using transfer learning from Pretrained Model <code>SSD MobileNet V2</code> from Tensorflow Model Zoo. The dataset used in this exercise taken from 
                                                    <a href="https://www.kaggle.com/datasets/andrewmvd/car-plate-detection" target="_blank">kaggle</a>.
                                                </p>
                                                    <p style="text-align: justify; text-justify: inter-word;">The file <code>1.PrepareDataset.py</code>performs Creation of necessary directories for organizing image and annotation files, Extracts image and annotation files from a downloaded zip file i.e. 
                                                        dataset downloaded from kaggle, Moves the image and annotation files to their respective directories, Splits the image and annotation files into train and test directories using a predefined ratio, 
                                                        Compresses the train and test directories into a tar.gz file.
                                                    </p>
                                                    <p style="text-align: justify; text-justify: inter-word;">
                                                        <code>2.ColabANPR_and_EasyOCR_ColabRun_v1.ipynb</code>, this does the Tensorflow Object Detection installation on google colab to utilize the power of GPU, create Label Map, Creates TF Records, 
                                                        Copy Model Config to Training Folder, Update Config For Transfer Learning, Train and Evaluate the model, Load Trained Model From Checkpoint and perform detection tasks from given images, webcam, and 
                                                        videos. It also converts the model to TFJS and TFLite for further usage.
                                                    </p>
                                                    <p style="text-align: justify; text-justify: inter-word;">
                                                        <code>2.Local_ANPR_Detection_and_EasyOCR.ipynb</code> doest the same things as above but it is for the local machine where GPU is not available.
                                                    </p>
                                                    <p style="text-align: justify; text-justify: inter-word;">
                                                        <code>3.DetectFromImage_EasyOCR.py</code>, <code>4.DetectFromRealTimeFeed_EasyOCR.py</code>, <code>5.DetectFromVideos_EasyOCR.py</code> are seperate scripts for object detection from images, webcam, 
                                                        videos respectively
                                                    </p>
                                                <p style="text-align: justify; text-justify: inter-word;">
                                                    <p><a href="https://github.com/mm-mazhar/Tensorflow-Object-Detection-Installation-and-ANPReasyOCR-Streamlit-App" target="_blank">Streamlit App</a></p>
                                                    <p><a href="https://youtu.be/syjWdTto2-o" target="_blank">Watch Demo</a></p>
                                                    <p>More on Github &nbsp; <a href="https://github.com/mm-mazhar/Automatic-Number-Plate-Recognition-and-EasyOCR" target="_blank" class="icon brands fa-github fa-2x"><span class="label">Github</span></a></p>
                                                </p>
                                                <!-- <br> -->
                                                <hr>
                                            <!-- Next -->
                                            <h2>Yolo v5 | Streamlit App | Road Sign Detection</h2>
                                                <p style="text-align: justify; text-justify: inter-word;">
                                                    <span class="image left">
                                                        <a href="./images/roadsigndetection.jpg" target="_blank">
                                                            <img src="./images/roadsigndetection.jpg" alt="" style="width:416; height:256" />
                                                        </a>
                                                    </span>
                                                    The goal of this exercise is to detect road signs from given images, webcam and videos. Dataset is taken from kaggle. <code>Yolov5_Colab_CustomModel_Training.ipynb</code> performs Yolo v5 Custom Training
                                                    which involves cloning the github repo of YoloV5, Installing requirements, Unzipping Dataset and Moving data.yaml, Checking and defining the number of classes in our dataset, Model configuration for YoloV5,
                                                    Customize iPython writefile so we can write variables, Model Configuration for our Model, Doing Changes in train.py for training, Training, and Inferencing with our custom Trained Model.
                                                </p>
                                                <p style="text-align: justify; text-justify: inter-word;">
                                                    <p><a href="https://github.com/mm-mazhar/Yolo-v5-Streamlit-App-Road-Sign-Detection/blob/main/app.py" target="_blank">Streamlit App</a></p>
                                                    <p><a href="https://youtu.be/l0yEcua5HEw" target="_blank">Watch Demo</a></p>
                                                    <p>More on Github &nbsp; <a href="https://github.com/mm-mazhar/Yolo-v5-Streamlit-App-Road-Sign-Detection" target="_blank" class="icon brands fa-github fa-2x"><span class="label">Github</span></a></p>
                                                </p>
                                                <!-- <br> -->
                                                <hr>
                                            <!-- Next -->
                                            <h2>Yolo V5 | Streamlit App | Multiple Object Detection on Pretrained Model</h2>
                                                <p style="text-align: justify; text-justify: inter-word;">
                                                    <span class="image right">
                                                        <a href="./images/YoloV5MultipleObjectDetection_onPretrained Model.jpg" target="_blank">
                                                            <img src="./images/YoloV5MultipleObjectDetection_onPretrained Model.jpg" alt="" style="width:416; height:256" />
                                                        </a>
                                                    </span>
                                                    This Python code is for a Streamlit app that uses YOLOv5, an object detection model, to perform object detection on a user-supplied image or video, or from a live video feed. The app allows the user to select
                                                    which device to use for inference (CPU or GPU), the minimum confidence score threshold, and which classes of objects to detect. The app displays the detected objects in the input media and their corresponding
                                                    confidence scores. The code imports necessary libraries, such as Streamlit, OpenCV and defines a few helper functions, including one to get the latest folder in a certain directory, which is used to get the 
                                                    latest output folder for the detection results, and another to get all subdirectories in a certain path. The main function is defined to run the Streamlit app. The app has a sidebar that allows the user to 
                                                    select the activity (image, video, or live feed), select the device, select the minimum confidence score threshold, and select which object classes to detect. The app also displays the selected input media 
                                                    and detected objects with their confidence scores.
                                                </p>
                                                <p style="text-align: justify; text-justify: inter-word;">    
                                                    <p>Streamlit App: <a href="https://youtu.be/xTq5YP5gHSo" target="_blank">Watch Demo</a></p>
                                                    <p>More on Github &nbsp; <a href="https://github.com/mm-mazhar/Yolo-v5-Streamlit-App-Pretrained-Model" target="_blank" class="icon brands fa-github fa-2x"><span class="label">Github</span></a></p>
                                                </p>
                                                <!-- <br> -->
                                                <hr>
                                            <!-- Next -->
                                            <h2>Face Mask Detection</h2>
                                                <p style="text-align: justify; text-justify: inter-word;">
                                                    <span class="image left">
                                                        <a href="./images/facemaskdetection.jpg" target="_blank">
                                                            <img src="./images/facemaskdetection.jpg" alt="" style="width:416; height:256" />
                                                        </a>
                                                    </span>
                                                    Goal of this exercise is to detect whether the person is wearing a face mask or not. As usual dataset is taken from <a href="https://www.kaggle.com/code/jiaowoguanren/face-mask-detection-tensorflow-cnn-resmlp/data" target="_blank">kaggle</a>.
                                                    <code>2.Colab_Training_and_Detection.ipynb</code> script does the Tensorflow Object Detection installation on google colab to utilize the power of GPU, create Label Map, Creates TF Records, 
                                                    Copy Model Config to Training Folder, Update Config For Transfer Learning, Train and Evaluate the model, Load Trained Model From Checkpoint and perform detection tasks from given images, webcam, and 
                                                    videos. It also converts the model to TFJS and TFLite for further usage.
                                                </p>
                                                <p style="text-align: justify; text-justify: inter-word;">
                                                    <p>More on Github &nbsp; <a href="https://github.com/mm-mazhar/Face-Mask-Detection" target="_blank" class="icon brands fa-github fa-2x"><span class="label">Github</span></a></p>
                                                </p>
                                                <!-- <br> -->
                                                <hr>
                                            <!-- Next -->
                                            <h2>Image Classification | Detect Infected Blood Cells of Maleria Bacteria</h2>
                                                <p style="text-align: justify; text-justify: inter-word;">
                                                    <span class="image right">
                                                        <a href="./images/MaleriaBacteriaDetect.png" target="_blank">
                                                            <img src="./images/MaleriaBacteriaDetect.png" alt="" style="width:416; height:256" />
                                                        </a>
                                                    </span>
                                                    This is a web application for detecting malaria using a pre-trained deep learning model. The application is built using the Streamlit framework, which makes it easy to create and share interactive 
                                                    data applications. The app starts by importing the necessary libraries, including Streamlit and Keras for loading the pre-trained model. It also imports a custom module called "FilesUpload," which is 
                                                    used to handle file uploads from the user interface. The pre-trained model is loaded from disk, and the image is passed through the model for prediction. The output is displayed as either 
                                                    "Infected/Parasitized" or "Uninfected," along with the probability of the prediction.
                                                </p>
                                                <p style="text-align: justify; text-justify: inter-word;">    
                                                    <p>Data Source: <a href="https://ceb.nlm.nih.gov/repositories/malaria-datasets/" target="_blank">Official NIH Website</a></p>
                                                    <p>Streamlit App: <a href="https://mazqoty-malaria-detection-app-9d0gj6.streamlit.app" target="_blank">Watch Demo</a></p>
                                                    <p>More on Github &nbsp; <a href="https://github.com/mm-mazhar/malaria_detection" target="_blank" class="icon brands fa-github fa-2x"><span class="label">Github</span></a></p>
                                                </p>
                                                <!-- <br> -->
                                                <hr>
                                            <!-- Next -->
                                            <h2>Convolutional neural network (CNN) | CIFAR-100 dataset</h2>
                                                <p style="text-align: justify; text-justify: inter-word;">
                                                    <span class="image left">
                                                        <a href="./images/cnn_cifar100.jpg" target="_blank">
                                                            <img src="./images/cnn_cifar100.jpg" alt="" style="width:416; height:256" />
                                                        </a>
                                                    </span>
                                                    The recognition of images in this project has been done using transfer learning approach. The network built in this project uses the state-of-the-art EfficientNet-B0 which was trained on the popular, 
                                                    challenging and large ImageNet dataset. Transfer learning and the idea of intelligently scaling the network (carefully balancing the network's width, depth and resolution) helped in getting a good performance
                                                    on this dataset. By just training the model for 11 epochs, the model managed to achieve an accuracy of 81 percent. The training of the model has been done on a GPU and the model has also been tested on some 
                                                    new random images to visualize the top 5 category predictions along with their probabilities. 
                                                </p>
                                                    
                                                
                                                
                                                <p style="text-align: justify; text-justify: inter-word;">
                                                    <p>Data Source: <a href="https://www.cs.toronto.edu/~kriz/cifar.html" target="_blank">Kaggle/Cifar-10 and Cifar-100 datasets</a> The dataset contains 3 folders - Meta, Train, Test. </p>
                                                    <p>More on Github &nbsp; <a href="https://github.com/mm-mazhar/CNN_CIFAR100" target="_blank" class="icon brands fa-github fa-2x"><span class="label">Github</span></a></p>
                                                <!-- <br> -->
                                                <hr>
                                            <!-- Next -->
                                            
                                        </div>
                                    </div>
                            </section>
						</div>
					</div>

				<!-- Sidebar -->
				<div id="sidebar">
					<div class="inner">
						<!-- Menu -->
							<nav id="menu">
								<div class="theme-buttons">
									<button id="toggle" class="button">Switch Mode <img src="images/moon.png" id="icon" class="icon-themes"></button>
								</div>
								<header class="major">
									<!-- <a href="#menu"><h2>Menu</h2></a> -->
									<h2>Menu</h2>
								</header>
								<ul>
									<!-- <li><a href="/index.html">Homepage</a></li> -->
									<li><a href="./">Homepage</a></li>
									<!-- <li><a href="#latest-work">Latest</a></li> -->
									<li><a href="./dataanalysiswithpython.html">Data Analysis with Python</a></li>
									<li><a href="./mldlcv.html">ML/DL and Computer Vision</a></li>
									<li><a href="./genai.html">Generative AI</a></li>
									<li><a href="./pythonpackages.html">Python Packages</a></li>
									<li><a href="./sqlandpowerbi.html">SQL & Power BI</a></li>
									<li><a href="./webscrapingandothers.html">Web Scraping & Others</a></li>
							
									<!-- <li><a href="generic.html">Generic</a></li>
												<li><a href="elements.html">Elements</a></li> -->
								  </ul>
							</nav>

						<!-- Section -->
							<section>
								<header class="major">
									<h2>Get in touch</h2>
								</header>
								<!-- <p>Sed varius enim lorem ullamcorper dolore aliquam aenean ornare velit lacus, ac varius enim lorem ullamcorper dolore. Proin sed aliquam facilisis ante interdum. Sed nulla amet lorem feugiat tempus aliquam.</p> -->
								<ul class="contact">
									<li class="icon solid fa-envelope"><a href="mazqoty.01@gmail.com" target="_blank">mazqoty.01@gmail.com</a></li>
									<!-- <li class="icon solid fa-phone">(000) 000-0000</li> -->
									<!-- <li class="icon solid fa-phone"><a href="https://wa.me/+923002576068" target="_blank">Send Message on WhatsApp</a></li> -->
									<li class="icon solid brands fa-whatsapp"><a href="https://wa.me/+923002576068" target="_blank">Send Message on WhatsApp</a></li>
									<li class="icon brands fa-github"><a href="https://github.com/mm-mazhar/mazhar" target="_blank">Github</a></li>
									<li class="icon brands fa-linkedin"><a href="https://www.linkedin.com/in/m-mazhar-121133269/" target="_blank">Linkedin</a></li>
									<!-- <li class="icon brands fa-twitter"><a href="https://twitter.com/mm_mazhar19" target="_blank">Twitter</a></li> -->
									
									<!-- <li class="icon solid fa-home">1234 Somewhere Road #8254<br />
									Nashville, TN 00000-0000</li> -->
								</ul>
							</section>


						<!-- Footer -->
							<footer id="footer">
								<p class=" © copyright">&copy; M. Mazhar Made with ❤️   +  <a href="https://html5up.net">HTML5 UP</a></p>
								
							</footer>

					</div>
				</div>

			</div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>
			<script>
				const toggle = document.getElementById("toggle");
				const refresh = document.getElementById("refresh");
				const theme = window.localStorage.getItem("theme");
				var icon=document.getElementById("icon");

				/* checks if the theme stored in localStorage is dark
				if yes apply the dark theme to the body */
				if (theme === "dark") {
					document.body.classList.add("dark");
					icon.src="images/sun.png";
				}

				// event listener stops when the change theme button is clicked
				toggle.addEventListener("click", () => {
				document.body.classList.toggle("dark");
				if (theme === "dark") {
					icon.src="images/sun.png";
					window.localStorage.setItem("theme", "light");
					window.location.reload();
				} else {
					icon.src="images/moon.png";
					window.localStorage.setItem("theme", "dark");
					window.location.reload();
				}
				});
			</script>

			<script>
				var tablinks=document.getElementsByClassName("tab-links");
				var tabcontents=document.getElementsByClassName("tab-contents");
				
				function opentab(tabname){
					for(tablink of tablinks){
						tablink.classList.remove("active-link");
					}
					for(tabcontent of tabcontents){
						tabcontent.classList.remove("active-tab");
					}
					event.currentTarget.classList.add("active-link");
					document.getElementById(tabname).classList.add("active-tab");
				}
			</script>


	</body>
</html>